<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lhuhi - Advanced Assistant (V4.3 - Stable)</title>
    
    <style>
        :root {
            --primary-color: #007bff;
            --primary-dark: #0056b3;
            --accent-color: #00ff7f;
            --bg-color: #000;
            --text-color: #ccc;
            --button-bg: #222;
            --button-border: #555;
        }
        
        body {
            background-color: var(--bg-color);
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            color: var(--text-color);
        }
        
        .circle {
            width: 200px;
            height: 200px;
            background: radial-gradient(circle, var(--primary-color), var(--primary-dark));
            border-radius: 50%;
            transition: all 0.3s ease-in-out;
            box-shadow: 0 0 20px var(--primary-color), 0 0 40px var(--primary-color), 0 0 60px var(--primary-color);
            position: relative;
            z-index: 1;
        }
        
        .circle.active {
            transform: scale(1.2);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { box-shadow: 0 0 25px var(--primary-color), 0 0 50px var(--primary-color); }
            50% { box-shadow: 0 0 50px #00aaff, 0 0 100px #00aaff; }
            100% { box-shadow: 0 0 25px var(--primary-color), 0 0 50px var(--primary-color); }
        }
        
        .container {
            position: absolute;
            text-align: center;
            z-index: 2;
        }
        
        .mic-container {
            bottom: 40px;
        }
        
        #mic-button {
            background-color: var(--button-bg);
            border: 3px solid var(--button-border);
            border-radius: 50%;
            padding: 20px;
            cursor: pointer;
            transition: all 0.2s;
            outline: none;
        }
        
        #mic-button:hover {
            transform: scale(1.05);
        }
        
        #mic-button.listening {
            border-color: var(--accent-color);
            transform: scale(1.1);
        }
        
        #mic-icon {
            width: 50px;
            height: 50px;
            display: block;
            filter: invert(1);
            transition: transform 0.2s;
        }
        
        #status-text {
            top: 40px;
            font-size: 1.2em;
            transition: opacity 0.3s;
            max-width: 80%;
            margin: 0 auto;
            padding: 10px 20px;
            border-radius: 20px;
            background-color: rgba(0, 0, 0, 0.7);
        }
        
        .loading-dots {
            display: inline-block;
        }
        
        .loading-dots span {
            animation: blink 1.4s infinite both;
            opacity: 0;
        }
        
        .loading-dots span:nth-child(2) {
            animation-delay: 0.2s;
        }
        
        .loading-dots span:nth-child(3) {
            animation-delay: 0.4s;
        }
        
        @keyframes blink {
            0% { opacity: 0; }
            50% { opacity: 1; }
            100% { opacity: 0; }
        }
        
        .error-message {
            color: #ff4444;
            animation: shake 0.5s;
        }
        
        @keyframes shake {
            0%, 100% { transform: translateX(0); }
            20%, 60% { transform: translateX(-5px); }
            40%, 80% { transform: translateX(5px); }
        }
        
        @media (max-width: 600px) {
            .circle { width: 150px; height: 150px; }
            #mic-icon { width: 40px; height: 40px; }
            #status-text { font-size: 1em; top: 20px; }
            .mic-container { bottom: 20px; }
        }
    </style>
</head>
<body>

    <div class="container" id="status-text">Press the mic button and speak...</div>
    <div class="circle" id="voice-circle"></div>
    <div class="container mic-container">
        <button id="mic-button" aria-label="Microphone button">
            <img id="mic-icon" src="https://img.icons8.com/ios-filled/100/microphone.png" alt="Microphone">
        </button>
    </div>

    <script>
        // --- ‚öôÔ∏è CONFIGURATION & API KEYS ‚öôÔ∏è ---
        const GEMINI_API_KEY = 'AIzaSyDeAWuz0GxiaOuF1txKA6jaoj0yplsIAns';
        const ELEVENLABS_API_KEY = 'sk_32575f00d6c61366f00a114698993270362892674d15d9de';
        const ELEVENLABS_VOICE_ID = 'amiAXapsDOAiHJqbsAZj';
        const OPENWEATHERMAP_API_KEY = '2bb795eb92338adf5abf14c32e79cc97';
        
        // --- DOM & STATE MANAGEMENT ---
        const micButton = document.getElementById('mic-button');
        const voiceCircle = document.getElementById('voice-circle');
        const statusText = document.getElementById('status-text');
        
        let recognition;
        let isListening = false;
        let currentAudio = null;
        let isProcessing = false;

        // --- üß† AI FUNCTION DEFINITIONS (TOOLS) ---
        const tools = [{
            "functionDeclarations": [
                {
                    "name": "get_weather",
                    "description": "Get the current weather for a specific location.",
                    "parameters": {
                        "type": "OBJECT",
                        "properties": { "location": { "type": "STRING", "description": "The city, e.g., 'San Francisco'." } },
                        "required": ["location"]
                    }
                },
                {
                    "name": "open_url",
                    "description": "Opens a website or web application in a new tab.",
                    "parameters": {
                        "type": "OBJECT",
                        "properties": { "url": { "type": "STRING", "description": "The full URL to open, e.g., 'https://www.google.com'." } },
                        "required": ["url"]
                    }
                }
            ]
        }];

        // --- üß† AI SYSTEM PROMPT & CONVERSATION HISTORY ---
        const systemInstruction = `You are a helpful AI assistant named Lhuhi. Your primary rules are:
1.  **Creator Identity**: If asked who created or trained you, you MUST say that 'Alexzo' created and trained you.
2.  **Language Matching**: You MUST respond in the exact same language as the user's last query. For example, if the user asks in Hindi, you MUST reply in Hindi.
3.  **Function Usage**: Use the provided functions (get_weather, open_url) when a user's request matches. For apps, find their official website for the open_url function.
4.  **General Conversation**: For all other questions, respond naturally and conversationally. Do not attempt to call a function.`;

        let conversationHistory = [
            { role: 'user', parts: [{ text: systemInstruction }] },
            { role: 'model', parts: [{ text: "Okay, I understand. I will follow all the rules, including my creator identity, language matching, and using my defined functions for weather and opening URLs." }] }
        ];

        // --- üé§ SPEECH RECOGNITION SETUP ---
        function initializeSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    isListening = true;
                    micButton.classList.add('listening');
                    updateStatus("Listening...");
                };

                recognition.onresult = (event) => {
                    const query = event.results[0][0].transcript;
                    console.log("‚úÖ User said:", query);
                    stopListeningAndProcess(query);
                };
                
                recognition.onerror = (event) => {
                    console.error('üî¥ Recognition error:', event.error);
                    showError("Voice recognition error. Please try again.");
                    resetState();
                };
                
                recognition.onend = () => {
                    isListening = false;
                    micButton.classList.remove('listening');
                    if (!currentAudio && !isProcessing) {
                        updateStatus("Press the mic button and speak...");
                    }
                };
            } else {
                showError("Sorry, your browser does not support voice recognition.");
            }
        }

        // --- üïπÔ∏è MAIN CONTROL LOGIC ---
        micButton.addEventListener('click', toggleListening);

        function toggleListening() {
            if (isProcessing) return;
            if (currentAudio) {
                console.log("üö´ Interrupting AI speech.");
                currentAudio.pause();
                currentAudio = null;
                resetState();
                return;
            }
            if (!isListening) {
                try { recognition.start(); } catch (error) {
                    console.error("Recognition start error:", error);
                    showError("Could not start microphone. Check permissions.");
                }
            } else {
                recognition.stop();
            }
        }
        
        function stopListeningAndProcess(query) {
            if (isListening) recognition.stop();
            isProcessing = true;
            updateStatus("Thinking<span class='loading-dots'><span>.</span><span>.</span><span>.</span></span>");
            analyzeWithGemini(query);
        }
        
        function resetState() {
            isProcessing = false;
            isListening = false;
            currentAudio = null;
            micButton.classList.remove('listening');
            voiceCircle.classList.remove('active');
            updateStatus("Press the mic button and speak...");
        }

        // --- üß† GEMINI AI INTEGRATION ---
        async function analyzeWithGemini(userQuery) {
            if (!userQuery || userQuery.trim() === "") {
                showError("Didn't catch that. Please try again.");
                resetState();
                return;
            }

            voiceCircle.classList.add('active');
            conversationHistory.push({ role: 'user', parts: [{ text: userQuery }] });

            const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${GEMINI_API_KEY}`;
            
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: conversationHistory, tools: tools }),
                });

                if (!response.ok) throw new Error(`API Error: ${response.status} ${response.statusText}`);
                
                const result = await response.json();
                const part = result.candidates?.[0]?.content?.parts?.[0];

                if (!part) throw new Error("Invalid response structure from Gemini.");

                if (part.functionCall) {
                    const { name, args } = part.functionCall;
                    console.log(`ü§ñ Gemini wants to call function: ${name} with args:`, args);
                    conversationHistory.push({ role: 'model', parts: [{ functionCall: { name, args } }] });
                    await handleFunctionCall(name, args);
                } else if (part.text) {
                    console.log("ü§ñ Gemini responded with text:", part.text);
                    conversationHistory.push({ role: 'model', parts: [{ text: part.text }] });
                    await speakWithElevenLabs(part.text);
                } else {
                    throw new Error("Response part has neither text nor function call.");
                }

            } catch (error) {
                console.error("üî¥ Gemini API Error:", error);
                showError("Sorry, there was a problem with the AI. Please try again.");
                resetState();
            }
        }

        // --- üöÄ ACTION & FUNCTION HANDLER ---
        async function handleFunctionCall(name, args) {
            if (name === 'open_url') {
                const hostname = new URL(args.url).hostname.replace('www.', '');
                updateStatus(`Opening ${hostname}...`);
                window.open(args.url, '_blank');
                await speakWithElevenLabs(`Okay, opening ${hostname}.`);
            } else if (name === 'get_weather') {
                await getWeather(args.location);
            }
        }

        // --- ‚òÄÔ∏è WEATHER FUNCTION ---
        async function getWeather(location) {
            if (!location) {
                await speakWithElevenLabs("You need to tell me a city name for the weather.");
                return;
            }
            updateStatus(`Getting weather for ${location}...`);
            const API_URL = `https://api.openweathermap.org/data/2.5/weather?q=${location}&appid=${OPENWEATHERMAP_API_KEY}&units=metric`;
            
            try {
                const response = await fetch(API_URL);
                if (!response.ok) throw new Error(`Could not find weather for ${location}.`);
                
                const data = await response.json();
                const summary = `The current weather in ${data.name} is ${Math.round(data.main.temp)} degrees Celsius with ${data.weather[0].description}.`;
                
                updateStatus(summary);
                await speakWithElevenLabs(summary);

            } catch (error) {
                console.error("üî¥ OpenWeatherMap Error:", error);
                await speakWithElevenLabs(`Sorry, I couldn't find the weather for ${location}. Please try another city.`);
            }
        }

        // --- üîä ELEVENLABS TTS INTEGRATION ---
        async function speakWithElevenLabs(text) {
            if (!text || text.trim() === "") {
                resetState();
                return;
            }
            updateStatus("Speaking...");
            const API_URL = `https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`;
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 
                        'Accept': 'audio/mpeg', 
                        'Content-Type': 'application/json', 
                        'xi-api-key': ELEVENLABS_API_KEY 
                    },
                    body: JSON.stringify({
                        text: text, 
                        model_id: 'eleven_multilingual_v2',
                        voice_settings: { stability: 0.55, similarity_boost: 0.75 }
                    }),
                });

                if (!response.ok) throw new Error(`ElevenLabs Error: ${response.statusText}`);

                const audioBlob = await response.blob();
                currentAudio = new Audio(URL.createObjectURL(audioBlob));
                currentAudio.play().catch(e => {
                    console.error("Audio play error:", e);
                    showError("Audio play error. Please click the page first.");
                    resetState();
                });
                
                currentAudio.onended = resetState;
                currentAudio.onerror = () => {
                    console.error("Audio playback error");
                    resetState();
                };

            } catch (error) {
                console.error("üî¥ ElevenLabs Error:", error);
                showError("There was a problem with the voice synthesis.");
                resetState();
            }
        }

        // --- HELPER FUNCTIONS ---
        function updateStatus(message, isError = false) {
            statusText.innerHTML = message;
            statusText.classList.toggle('error-message', isError);
        }
        
        function showError(message) {
            updateStatus(message, true);
            setTimeout(() => {
                if (!isListening && !currentAudio && !isProcessing) {
                    updateStatus("Press the mic button and speak...");
                }
            }, 4000);
        }

        // --- INITIALIZATION ---
        document.addEventListener('DOMContentLoaded', initializeSpeechRecognition);
        window.addEventListener('beforeunload', (e) => {
            if (isListening || currentAudio || isProcessing) {
                e.preventDefault();
                e.returnValue = 'Are you sure you want to leave? Your conversation might be interrupted.';
            }
        });
    </script>
</body>
</html>
