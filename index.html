<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lhuhi - Voice Activated AI</title>
    
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400&display=swap');

        :root {
            --background-start: #0A0A10;
            --background-end: #000000;
            --text-color: #E2E8F0;
        }
        
        body {
            background: radial-gradient(circle, var(--background-start) 0%, var(--background-end) 100%);
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
            font-family: 'Poppins', sans-serif;
            color: var(--text-color);
        }
        
        #ui-container {
            position: relative;
            z-index: 2;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            width: 100%;
            height: 100%;
        }

        #animation-canvas {
            position: absolute;
            z-index: 1;
        }
        
        #status-text {
            position: absolute;
            font-size: 1.8em;
            font-weight: 300;
            z-index: 2;
            text-shadow: 0 0 15px rgba(0,0,0,0.7);
            transition: all 0.3s;
            max-width: 80%;
            text-align: center;
            opacity: 0; /* Hidden by default, shown on interaction */
        }
        
        #start-prompt {
            font-size: 2em;
            cursor: pointer;
            text-align: center;
            padding: 20px;
        }

        @media (max-width: 600px) {
            #status-text { font-size: 1.3em; }
            #start-prompt { font-size: 1.5em; }
        }
    </style>
</head>
<body>

    <canvas id="animation-canvas"></canvas>
    <div id="ui-container">
        <div id="status-text"></div>
        <div id="start-prompt">Click anywhere to activate Lhuhi</div>
    </div>

    <script>
        // --- âš™ï¸ CONFIGURATION & API KEYS âš™ï¸ ---
        const GEMINI_API_KEY = 'AIzaSyCChlQrgIHnISE7H1PmnhuVvSC7YMJyg9A';
        const WEATHER_API_KEY = '3a4d7ed40005449f9c0122940252606';
        const WAKE_WORD = "hey lhuhi"; // The hotword to activate the assistant
        
        // --- DOM & STATE ---
        const startPrompt = document.getElementById('start-prompt');
        const statusText = document.getElementById('status-text');
        
        let recognition;
        let isInitialized = false;
        let isAwake = false; // Is the assistant waiting for a command after hotword?
        let preferredVoice = null;
        let audioAnalyser;
        let audioDataArray;

        // --- CANVAS ANIMATION ---
        const canvas = document.getElementById('animation-canvas');
        const ctx = canvas.getContext('2d');
        const viz = {
            state: 'idle',
            angle: 0,
            amplitude: 0,
            targetAmplitude: 5,
            phase: 0
        };

        function setupCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        }

        function draw() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            const centerX = canvas.width / 2;
            const centerY = canvas.height / 2;

            if (viz.state === 'speaking') {
                drawWave(centerY);
            } else {
                drawOrb(centerX, centerY);
            }
            
            requestAnimationFrame(draw);
        }

        function drawOrb(cx, cy) {
            let rotationSpeed = 0.005;
            if (viz.state === 'idle') {
                viz.targetAmplitude = 5 + Math.sin(Date.now() / 500) * 3;
            } else if (viz.state === 'listening' || viz.state === 'awake') {
                rotationSpeed = 0.02;
                if (audioAnalyser) {
                    audioAnalyser.getByteFrequencyData(audioDataArray);
                    const avg = audioDataArray.reduce((a, b) => a + b) / audioDataArray.length;
                    viz.targetAmplitude = (avg / 255) * 40 + 5;
                }
            } else if (viz.state === 'thinking') {
                rotationSpeed = 0.1;
                viz.targetAmplitude = 25 + Math.random() * 10;
            }

            viz.angle += rotationSpeed;
            viz.amplitude += (viz.targetAmplitude - viz.amplitude) * 0.2;

            for (let i = 0; i < 3; i++) {
                ctx.beginPath();
                ctx.lineWidth = 1.5 + i * 1;
                const gradient = ctx.createLinearGradient(0, 0, canvas.width, 0);
                gradient.addColorStop(0, `hsl(${(viz.state === 'awake' ? 120 : viz.angle * 20 + i * 60) % 360}, 100%, 70%)`);
                gradient.addColorStop(1, `hsl(${(viz.state === 'awake' ? 120 : viz.angle * 20 + i * 60 + 180) % 360}, 100%, 70%)`);
                ctx.strokeStyle = gradient;

                for (let a = 0; a < Math.PI * 2; a += 0.02) {
                    const r = 80 + viz.amplitude * Math.sin(a * 5 + viz.angle + i * 2);
                    const x = cx + r * Math.cos(a + i * Math.PI / 3);
                    const y = cy + r * Math.sin(a + i * Math.PI / 3);
                    if (a === 0) ctx.moveTo(x, y);
                    else ctx.lineTo(x, y);
                }
                ctx.closePath();
                ctx.stroke();
            }
        }

        function drawWave(cy) {
            viz.phase += 0.1;
            viz.amplitude += (0 - viz.amplitude) * 0.1; 
            for (let i = 0; i < 3; i++) {
                ctx.beginPath();
                ctx.lineWidth = 2 + i * 2;
                ctx.strokeStyle = `hsla(${(200 + i * 30) % 360}, 100%, 70%, ${0.3 + viz.amplitude / 100})`;
                for (let x = 0; x < canvas.width; x++) {
                    const angle = (x / canvas.width) * Math.PI * 4 + viz.phase + i * 0.5;
                    const y = viz.amplitude * Math.sin(angle);
                    ctx.lineTo(x, cy + y);
                }
                ctx.stroke();
            }
        }
        
        // --- ðŸ§  AI SYSTEM PROMPT ---
        const systemInstruction = `You are Lhuhi, an AI assistant.
        **CRITICAL RULES:**
        1.  **Creator**: If asked who created you, say 'Alexzo' created and trained you.
        2.  **Language**: Respond in the user's language.
        3.  **Real-Time Actions**: When asked for real-time information, you MUST respond ONLY with the action's JSON object. **DO NOT add any conversational text.** The system will handle the spoken response.
            - For weather OR time in a specific city: \`{"action": "get_info_for_city", "location": "CITY_NAME"}\`.
            - To open a URL: \`{"action": "open_url", "url": "https://example.com"}\`.
            - For the user's LOCAL time: \`{"action": "get_local_time"}\`.
            - For the current date: \`{"action": "get_date"}\`.
        4.  **Conversation**: For ALL other questions, reply with clean, natural language. DO NOT output JSON.`;
        
        let conversationHistory = [
            { role: 'user', parts: [{ text: systemInstruction }] },
            { role: 'model', parts: [{ text: "Understood. For real-time queries, I will only output the JSON." }] }
        ];

        // --- ðŸŽ¤ INITIALIZATION (NOW WITH HOTWORD) ---
        async function initializeApp() {
            startPrompt.style.display = 'none';
            statusText.style.opacity = '1';
            try {
                if (!('webkitSpeechRecognition' in window) || !('speechSynthesis' in window) || !navigator.mediaDevices) {
                    throw new Error("Browser does not support required APIs.");
                }
                
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                audioAnalyser = audioContext.createAnalyser();
                audioAnalyser.fftSize = 256;
                source.connect(audioAnalyser);
                audioDataArray = new Uint8Array(audioAnalyser.frequencyBinCount);

                recognition = new webkitSpeechRecognition();
                recognition.continuous = true; // Always on
                recognition.interimResults = true;
                recognition.lang = 'en-US';

                recognition.onresult = handleRecognitionResult;
                recognition.onerror = (event) => { console.error('ðŸ”´ Recognition error:', event.error); };
                recognition.onend = () => {
                    // Automatically restart recognition to keep it always on
                    if (isInitialized) {
                        setTimeout(() => recognition.start(), 250);
                    }
                };

                speechSynthesis.onvoiceschanged = () => {
                    const voices = speechSynthesis.getVoices();
                    preferredVoice = voices.find(v => v.name.includes('Google') && v.lang.startsWith('en')) || 
                                   voices.find(v => v.name.includes('Zira') && v.lang.startsWith('en')) ||
                                   voices.find(v => v.lang.startsWith('en-US'));
                };
                
                isInitialized = true;
                setUIState('listening'); // Start listening for hotword
                recognition.start();
                console.log("âœ… System Initialized. Listening for hotword...");
            } catch (error) {
                console.error("ðŸ”´ Initialization failed:", error);
                setUIState('error', "Mic access failed.");
            }
        }
        
        function handleRecognitionResult(event) {
            let transcript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                transcript += event.results[i][0].transcript;
            }

            if (isAwake) {
                // If awake, the first final result is the command
                if (event.results[event.results.length - 1].isFinal) {
                    isAwake = false; // Consume the command
                    recognition.stop();
                    analyzeWithGemini(transcript);
                }
            } else if (transcript.toLowerCase().includes(WAKE_WORD)) {
                console.log("ðŸ”¥ Hotword Detected!");
                isAwake = true;
                setUIState('awake'); // Special state after hotword
            }
        }

        // --- UI & MAIN CONTROL ---
        function setUIState(state, message = '') {
            viz.state = state;
            statusText.textContent = message;
        }

        startPrompt.addEventListener('click', initializeApp, { once: true });

        // --- ðŸ§  GEMINI AI INTEGRATION ---
        async function analyzeWithGemini(userQuery) {
            if (!userQuery || !userQuery.trim()) {
                setUIState('idle'); return;
            }
            
            setUIState('thinking');
            // Remove the hotword from the query
            const command = userQuery.toLowerCase().replace(WAKE_WORD, '').trim();
            conversationHistory.push({ role: 'user', parts: [{ text: command }] });
            const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${GEMINI_API_KEY}`;
            
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: conversationHistory }),
                });
                if (!response.ok) throw new Error(`API Error: ${response.status}`);
                
                const result = await response.json();
                const geminiResponseText = result.candidates?.[0]?.content?.parts?.[0]?.text;
                if (!geminiResponseText) throw new Error("Empty response from Gemini.");

                console.log("ðŸ¤– Gemini responded:", geminiResponseText);
                conversationHistory.push({ role: 'model', parts: [{ text: geminiResponseText }] });

                let action = null;
                try { action = JSON.parse(geminiResponseText); } catch (e) {}
                
                if (action && action.action) {
                    await handleAction(action, command);
                } else if (geminiResponseText) {
                    await speakAndPlay(geminiResponseText);
                }

            } catch (error) {
                console.error("ðŸ”´ Gemini/Logic Error:", error);
                await speakAndPlay("I've run into a problem. Please try again.");
            }
        }
        
        // --- ðŸš€ ACTION HANDLER ---
        async function handleAction(action, userQuery) {
            try {
                switch (action.action) {
                    case 'open_url':
                        await speakAndPlay(`Opening ${new URL(action.url).hostname}`);
                        if (action.url) window.open(action.url, '_blank');
                        break;
                    case 'get_info_for_city':
                        const purpose = userQuery.toLowerCase().includes('time') ? 'time' : 'weather';
                        await getInfoForCity(action.location, purpose);
                        break;
                    case 'get_local_time': await handleLocalTime(); break;
                    case 'get_date': await handleDate(); break;
                    default: throw new Error("Unknown action.");
                }
            } catch (error) {
                console.error("ðŸ”´ Action Handling Error:", error);
                await speakAndPlay("I had trouble performing that action.");
            }
        }

        // --- FEATURES ---
        function getCurrentLocation() {
            return new Promise((resolve, reject) => {
                if (!navigator.geolocation) return reject(new Error("Geolocation is not supported."));
                setUIState('thinking');
                navigator.geolocation.getCurrentPosition(resolve, reject, { timeout: 10000 });
            });
        }
        
        async function handleLocalTime() {
            const now = new Date();
            const timeString = now.toLocaleTimeString('en-US', { hour: 'numeric', minute: 'numeric', hour12: true });
            await speakAndPlay(`The current time is ${timeString}.`);
        }
        
        async function handleDate() {
            const now = new Date();
            const dateString = now.toLocaleDateString('en-US', { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' });
            await speakAndPlay(`Today is ${dateString}.`);
        }

        async function getInfoForCity(location = null, purpose = 'weather') {
            let finalLocation = location;
            try {
                if (!finalLocation) {
                    const position = await getCurrentLocation();
                    finalLocation = `${position.coords.latitude},${position.coords.longitude}`;
                }
                setUIState('thinking');
                const API_URL = `https://api.weatherapi.com/v1/current.json?key=${WEATHER_API_KEY}&q=${finalLocation}`;
                const response = await fetch(API_URL);
                const data = await response.json();

                if (response.ok && data.location) {
                    const summary = purpose === 'time'
                        ? `The time in ${data.location.name} is ${new Date(data.location.localtime).toLocaleTimeString('en-US', { hour: 'numeric', minute: 'numeric', hour12: true })}.`
                        : `The weather in ${data.location.name} is ${Math.round(data.current.temp_c)} degrees with ${data.current.condition.text}.`;
                    await speakAndPlay(summary);
                } else {
                    throw new Error(data.error?.message || "Invalid city data.");
                }
            } catch (error) {
                console.error("ðŸ”´ Weather/Location Error:", error);
                await speakAndPlay(`Sorry, I couldn't get the information. ${error.message}`);
            }
        }

        // --- ðŸ”Š BROWSER TTS FUNCTION (BULLETPROOF VERSION) ---
        async function speakAndPlay(text) {
            const sanitizedText = text.replace(/[*_`#]/g, '').trim();
            if (!sanitizedText || !('speechSynthesis' in window)) return;
            
            setUIState('speaking');
            
            return new Promise((resolve, reject) => {
                speechSynthesis.cancel(); 

                const utterance = new SpeechSynthesisUtterance(sanitizedText);
                if (preferredVoice) utterance.voice = preferredVoice;
                
                utterance.onboundary = (event) => {
                    viz.amplitude = 50 + Math.random() * 20;
                };

                const checkInterval = setInterval(() => {
                    if (!speechSynthesis.speaking) {
                        clearInterval(checkInterval);
                        console.log("âœ… Speech finished successfully.");
                        resolve();
                    }
                }, 100);

                utterance.onerror = (event) => {
                    clearInterval(checkInterval);
                    console.error("ðŸ”´ SpeechSynthesis Error:", event.error);
                    reject(event.error);
                };
                
                setTimeout(() => {
                    speechSynthesis.speak(utterance);
                }, 50);
            });
        }
        
        // --- INITIALIZE & START ANIMATION ---
        setupCanvas();
        draw();
        window.addEventListener('resize', setupCanvas);

    </script>
</body>
</html>
