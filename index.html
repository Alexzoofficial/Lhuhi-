<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lhuhi - Voice Assistant (V3)</title>
    
    <style>
        body { background-color: #000; margin: 0; display: flex; justify-content: center; align-items: center; height: 100vh; overflow: hidden; font-family: sans-serif; color: #ccc; }
        .circle { width: 200px; height: 200px; background: radial-gradient(circle, #007bff, #0056b3); border-radius: 50%; transition: all 0.3s ease-in-out; box-shadow: 0 0 20px #007bff, 0 0 40px #007bff, 0 0 60px #007bff; }
        .circle.active { transform: scale(1.2); animation: pulse 1.5s infinite; }
        @keyframes pulse { 0% { box-shadow: 0 0 25px #007bff, 0 0 50px #007bff; } 50% { box-shadow: 0 0 50px #00aaff, 0 0 100px #00aaff; } 100% { box-shadow: 0 0 25px #007bff, 0 0 50px #007bff; } }
        .container { position: absolute; text-align: center; }
        .mic-container { bottom: 40px; }
        #mic-button { background-color: #222; border: 2px solid #555; border-radius: 50%; padding: 20px; cursor: pointer; transition: transform 0.2s, box-shadow 0.2s; }
        #mic-button:hover { transform: scale(1.1); box-shadow: 0 0 25px rgba(0, 123, 255, 0.9); }
        #mic-icon { width: 50px; height: 50px; display: block; filter: invert(1); }
        .mic-on { border-color: #007bff !important; }
        .mic-off .mic-icon { filter: invert(0.5) !important; }
        #status-text { top: 40px; font-size: 1.2em; transition: opacity 0.3s; }
    </style>
</head>
<body>

    <div class="container" id="status-text">Lhuhi ko activate karne ke liye 'Lhuhi' bolein...</div>
    <div class="circle" id="voice-circle"></div>
    <div class="container mic-container">
        <button id="mic-button">
            <img id="mic-icon" src="https://img.icons8.com/ios-filled/100/microphone.png" alt="Microphone">
        </button>
    </div>

    <script>
        // --- ‚öôÔ∏è CONFIGURATION & API KEYS ‚öôÔ∏è ---
        const GEMINI_API_KEY = 'YOUR_GEMINI_API_KEY'; // üëà YAHAN APNI KEY DAALEIN
        const ELEVENLABS_API_KEY = 'YOUR_NEW_11LABS_API_KEY'; // üëà YAHAN APNI KEY DAALEIN
        const ELEVENLABS_VOICE_ID = 'amiAXapsDOAiHJqbsAZj';
        const WAKE_WORD = "lhuhi";

        // ---  DOM & STATE ---
        const micButton = document.getElementById('mic-button');
        const micIcon = document.getElementById('mic-icon');
        const voiceCircle = document.getElementById('voice-circle');
        const statusText = document.getElementById('status-text');
        
        let isListeningForCommand = false;
        let isSpeaking = false;
        let recognition;
        
        // --- üé§ SPEECH RECOGNITION (INPUT) üé§ ---
        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'hi-IN';

            recognition.onresult = (event) => {
                let final_transcript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        final_transcript += event.results[i][0].transcript;
                    }
                }
                
                const query = final_transcript.trim().toLowerCase();
                
                if (isListeningForCommand && query) {
                    console.log("‚úÖ Command received:", query);
                    stopListeningForCommand();
                    analyzeWithGemini(query);
                } else if (query.includes(WAKE_WORD) && !isSpeaking && !isListeningForCommand) {
                    console.log("üëÇ Wake word detected!");
                    startListeningForCommand();
                }
            };
            
            recognition.onerror = (event) => { console.error('üî¥ Recognition error:', event.error); };
            recognition.onend = () => { recognition.start(); };
            
            recognition.start(); // Start listening for wake word on page load
            console.log("üé§ Voice recognition system is ON. Waiting for wake word...");

        } else { alert('Sorry, your browser does not support voice recognition.'); }

        // --- üïπÔ∏è CONTROL FUNCTIONS üïπÔ∏è ---
        function startListeningForCommand() {
            isListeningForCommand = true;
            voiceCircle.classList.add('active');
            micButton.classList.add('mic-on');
            statusText.textContent = "Sun raha hun...";
            speakWithBrowserTTS("Ji boliye"); // Quick feedback
        }

        function stopListeningForCommand() {
            isListeningForCommand = false;
            voiceCircle.classList.remove('active');
            micButton.classList.remove('mic-on');
            statusText.textContent = `Lhuhi ko activate karne ke liye '${WAKE_WORD}' bolein...`;
        }

        micButton.addEventListener('click', () => {
            if (!isListeningForCommand) {
                startListeningForCommand();
            } else {
                stopListeningForCommand();
            }
        });

        // --- üß† GEMINI AI (THE BRAIN) üß† ---
        async function analyzeWithGemini(userQuery) {
            statusText.textContent = "Soch raha hun...";
            const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${GEMINI_API_KEY}`;
            
            // <<< YEH PROMPT SABSE ZAROORI HAI, ISE BEHTAR KIYA GAYA HAI >>>
            const prompt = `You are Lhuhi, an intelligent voice assistant. Your job is to understand the user's command and respond ONLY with a JSON object.
User command: "${userQuery}"

Available actions are "open_website" and "general_query".

1.  If the user wants to open a well-known website (like Google, YouTube, Facebook, Wikipedia, etc.), use the "open_website" action. The "data" must be the full, correct URL.
    - "YouTube kholo" -> {"action": "open_website", "data": "https://www.youtube.com"}
    - "open Google" -> {"action": "open_website", "data": "https://www.google.com"}
    - "Wikipedia par jao" -> {"action": "open_website", "data": "https://www.wikipedia.org"}

2.  For EVERYTHING ELSE (general questions, conversations, telling a story, calculations, search queries like "who is..."), use the "general_query" action. The "data" must be the complete, helpful answer in Hindi.
    - "Bharat ke pradhan mantri kaun hain" -> {"action": "general_query", "data": "Bharat ke vartaman pradhan mantri Shri Narendra Modi hain."}
    - "ek kahani sunao" -> {"action": "general_query", "data": "Ek samay ki baat hai, ek ghane jangal mein ek chatur lomdi rehti thi..."}
    - "5 plus 5 kitna hota hai" -> {"action": "general_query", "data": "5 plus 5, 10 hota hai."}

Now, analyze the user command "${userQuery}" and provide only the clean JSON object.`;
            
            console.log("üß† Sending to Gemini...");
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] }),
                });

                if (!response.ok) { // <<< BEHTAR ERROR CHECKING >>>
                    const errorBody = await response.text();
                    throw new Error(`Gemini API Error: ${response.statusText} - ${errorBody}`);
                }

                const result = await response.json();
                console.log("üîç Gemini Raw Response:", result);
                
                // <<< BEHTAR JSON PARSING >>>
                const geminiResponseText = result.candidates[0].content.parts[0].text;
                const cleanJsonString = geminiResponseText.replace(/```json\n|\n```/g, '').trim();
                console.log("üîß Cleaned JSON String:", cleanJsonString);
                
                const actionObject = JSON.parse(cleanJsonString);
                console.log("‚úÖ Gemini Action Plan:", actionObject);
                await performAction(actionObject);

            } catch (error) {
                console.error("üî¥üî¥üî¥ FATAL ERROR with Gemini/JSON:", error);
                statusText.textContent = "Maaf kijiye, samajhne mein dikkat aa rahi hai.";
                await speakWithElevenLabs("Maaf kijiye, samajhne mein kuchh dikkat aa rahi hai. Kripya apni API key check karein.");
            }
        }

        // --- üöÄ ACTION HANDLER üöÄ ---
        async function performAction(actionObject) {
            const { action, data } = actionObject;

            switch (action) {
                case 'open_website':
                    console.log(`üöÄ Opening website: ${data}`);
                    statusText.textContent = `${new URL(data).hostname} khol raha hun...`;
                    await speakWithElevenLabs(`Theek hai, ${new URL(data).hostname} khol raha hun.`);
                    window.open(data, '_blank');
                    // Note: Browser might block this popup. User may need to allow popups for this site.
                    break;
                
                case 'general_query':
                default:
                    console.log(`üí¨ Answering: ${data}`);
                    statusText.textContent = "Jawab de raha hun...";
                    await speakWithElevenLabs(data);
            }
        }

        // --- üîä ELEVENLABS TTS (VOICE OUTPUT) üîä ---
        async function speakWithElevenLabs(text) {
            if (!text) {
                console.error("üî¥ ElevenLabs Error: Cannot speak empty text.");
                return;
            }
            isSpeaking = true;
            voiceCircle.classList.add('active');
            
            const API_URL = `https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`;
            
            console.log(`üó£Ô∏è Requesting audio from 11Labs for: "${text}"`);
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 'Accept': 'audio/mpeg', 'Content-Type': 'application/json', 'xi-api-key': ELEVENLABS_API_KEY },
                    body: JSON.stringify({
                        text: text,
                        model_id: 'eleven_multilingual_v2',
                        voice_settings: { stability: 0.55, similarity_boost: 0.75 },
                    }),
                });

                if (!response.ok) {
                    throw new Error(`ElevenLabs API Error: ${response.statusText}`);
                }

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                audio.play();

                audio.onended = () => {
                    console.log("‚úÖ Speech finished.");
                    isSpeaking = false;
                    stopListeningForCommand(); // Reset to initial state
                };

            } catch (error) {
                console.error("üî¥üî¥üî¥ FATAL ERROR with ElevenLabs:", error);
                isSpeaking = false;
                stopListeningForCommand();
            }
        }
        
        // --- Fallback Browser TTS for quick non-API responses ---
        function speakWithBrowserTTS(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'hi-IN';
            window.speechSynthesis.speak(utterance);
        }
    </script>
</body>
</html>
