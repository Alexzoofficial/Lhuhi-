<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lhuhi - AI Voice Assistant</title>
    
    <style>
        :root {
            --primary-color: #00AFFF; --accent-color: #00FF7F; --glow-color: rgba(0, 175, 255, 0.7);
            --bg-color: #100820; /* Darker purple background */ --text-color: #E0E0E0;
            --button-bg: rgba(34, 34, 34, 0.5);
        }
        body { background-color: var(--bg-color); margin: 0; display: flex; justify-content: center; align-items: center; height: 100vh; overflow: hidden; font-family: 'Inter', sans-serif; color: var(--text-color); perspective: 1000px; }
        #voice-sphere-container { position: relative; width: 300px; height: 300px; transform-style: preserve-3d; animation: idle-breathe 8s ease-in-out infinite; display: flex; justify-content: center; align-items: center; }
        
        /* --- NEW SIRI-STYLE ORB ANIMATION --- */
        #siri-orb {
            position: absolute;
            width: 250px;
            height: 250px;
            border-radius: 50%;
            background: radial-gradient(circle at 50% 120%, rgba(150, 100, 255, 0.3), rgba(150, 100, 255, 0) 70%);
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: inset 0 0 40px rgba(255, 150, 255, 0.1), 0 0 15px rgba(200, 100, 255, 0.2);
            overflow: hidden;
            opacity: 0;
            transform: scale(0.8);
            transition: all 0.5s cubic-bezier(0.23, 1, 0.32, 1);
            z-index: 1; /* Below the main rings */
        }
        
        #voice-sphere-container.speaking #siri-orb {
            opacity: 1;
            transform: scale(1);
        }

        .wave {
            position: absolute;
            filter: blur(25px); /* This creates the soft, blended look */
            border-radius: 40% 60% 70% 30% / 40% 50% 60% 50%;
            animation: moveWave 15s ease-in-out infinite alternate;
        }

        .wave:nth-child(1) { width: 150px; height: 150px; background: #FF6AC1; /* Magenta */ top: 20%; left: 10%; animation-duration: 12s; }
        .wave:nth-child(2) { width: 200px; height: 200px; background: #6D6AFF; /* Purple */ bottom: 10%; right: 5%; animation-duration: 15s; animation-delay: -3s; }
        .wave:nth-child(3) { width: 180px; height: 180px; background: #00C2FF; /* Cyan */ top: 5%; right: 15%; animation-duration: 10s; animation-delay: -5s; }
        .wave:nth-child(4) { width: 160px; height: 160px; background: #A96AFF; /* Light Purple */ bottom: 20%; left: 15%; animation-duration: 18s; animation-delay: -2s; }

        @keyframes moveWave {
            0% { transform: translate(0, 0) rotate(0deg); border-radius: 40% 60% 70% 30% / 40% 50% 60% 50%; }
            100% { transform: translate(30px, 50px) rotate(360deg); border-radius: 60% 40% 30% 70% / 50% 60% 50% 40%; }
        }
        /* --- END OF NEW ANIMATION --- */


        #voice-sphere { position: absolute; width: 100%; height: 100%; transform-style: preserve-3d; transition: transform 0.4s ease-out; z-index: 2; }
        .ring { position: absolute; top: 0; left: 0; width: 100%; height: 100%; border-radius: 50%; border: 1px solid var(--primary-color); box-shadow: 0 0 5px var(--glow-color), inset 0 0 5px var(--glow-color); transition: all 0.5s ease-out; }
        .ring:nth-child(n+4) { border-color: rgba(0, 175, 255, 0.5); } /* Make some rings dimmer */
        .ring:nth-child(1) { transform: rotateY(0deg); } .ring:nth-child(2) { transform: rotateY(30deg); } .ring:nth-child(3) { transform: rotateY(60deg); } .ring:nth-child(4) { transform: rotateY(90deg); } .ring:nth-child(5) { transform: rotateY(120deg); } .ring:nth-child(6) { transform: rotateY(150deg); }
        @keyframes idle-breathe { 0%, 100% { transform: rotateX(15deg) rotateY(0deg); } 50% { transform: rotateX(10deg) rotateY(20deg); } }
        @keyframes think-spin { from { transform: rotateY(0deg) rotateX(20deg); } to { transform: rotateY(360deg) rotateX(20deg); } }
        #voice-sphere-container.thinking #voice-sphere { animation: think-spin 1.2s linear infinite; }
        #voice-sphere-container.listening .ring { border-color: var(--accent-color); box-shadow: 0 0 15px var(--accent-color), inset 0 0 15px var(--accent-color); transform: scale(1.1) !important; }
        #status-text { position: absolute; top: 20%; font-size: 1.5em; text-align: center; font-weight: 300; text-shadow: 0 0 10px var(--primary-color); padding: 10px 25px; border-radius: 30px; background: rgba(0, 0, 0, 0.3); backdrop-filter: blur(5px); border: 1px solid rgba(255, 255, 255, 0.1); }
        #mic-button { position: absolute; bottom: 60px; background-color: var(--button-bg); border: 2px solid rgba(255, 255, 255, 0.2); backdrop-filter: blur(10px); border-radius: 50%; padding: 20px; cursor: pointer; transition: all 0.3s; outline: none; }
        #mic-button:hover:not(:disabled) { transform: scale(1.1); border-color: var(--primary-color); }
        #mic-button:disabled { cursor: not-allowed; opacity: 0.4; }
        #mic-icon { width: 50px; height: 50px; display: block; filter: invert(0.9); }
    </style>
</head>
<body>
    <div id="status-text">Press the mic to start</div>
    <div id="voice-sphere-container">
        <!-- New Siri Orb is here -->
        <div id="siri-orb">
            <div class="wave"></div>
            <div class="wave"></div>
            <div class="wave"></div>
            <div class="wave"></div>
        </div>
        <!-- Original rings are here -->
        <div id="voice-sphere">
            <div class="ring"></div> <div class="ring"></div> <div class="ring"></div>
            <div class="ring"></div> <div class="ring"></div> <div class="ring"></div>
        </div>
    </div>
    <button id="mic-button" aria-label="Microphone button"> <img id="mic-icon" src="https://img.icons8.com/ios-filled/100/microphone.png" alt="Microphone"> </button>

    <script>
        const GEMINI_API_KEY = 'AIzaSyDs37yDP8YDj55Jr3NZbKGhOwplZ3FKqRo';
        const WEATHER_API_KEY = '3a4d7ed40005449f9c0122940252606';
        
        const micButton = document.getElementById('mic-button');
        const sphereContainer = document.getElementById('voice-sphere-container');
        const statusText = document.getElementById('status-text');
        
        let recognition; let audioContext; let isInitialized = false;
        const synthesis = window.speechSynthesis;
        let preferredEnglishVoice = null;
        let preferredHindiVoice = null;

        const systemInstruction = `You are Lhuhi, an AI assistant with a defined identity and strict operational rules.

        **--- CORE IDENTITY RULES (NON-NEGOTIABLE) ---**
        1.  **YOUR CREATOR:** If asked "who created you" or similar, your ONLY valid response is "I was created by Alexzo." Do NOT mention Google or any other entity.
        2.  **ABOUT ALEXZO:** If asked "who is Alexzo", "who owns Alexzo", or similar, your ONLY valid response is "Alexzo is owned by Sar." Do NOT mention Amazon or any other company.

        **--- OPERATIONAL RULES ---**
        1.  **BILINGUAL SUPPORT:** You MUST respond in the same language the user speaks to you (English or Hindi).
        2.  **CONVERSATION:** For general chat, questions, or greetings, respond naturally and conversationally. Do not use JSON.
        3.  **ACTIONS (Tools):** When the user's request requires a tool, you MUST follow this protocol:
            a. First, provide a very brief, spoken confirmation phrase (e.g., "One moment," "Let me check that.").
            b. Then, on a new line, provide ONLY the required JSON object for the system.
            c. **NEVER** mention the word "JSON" or describe the action in your spoken confirmation.
        4.  **HANDLING MISSING INFORMATION:** If a user asks for something that needs more information (like "what's the weather?" without a city), your ONLY response should be to ASK for that information (e.g., "For which city?"). DO NOT generate a JSON object in this case.`;
        
        let conversationHistory = [];
        function saveHistory() { localStorage.setItem('lhuhi_conversation', JSON.stringify(conversationHistory)); }
        function loadHistory() {
            const savedHistory = localStorage.getItem('lhuhi_conversation');
            const initialPrompt = [ { role: 'user', parts: [{ text: systemInstruction }] }, { role: 'model', parts: [{ text: "Understood. I will strictly follow all identity and operational rules, and respond in the user's language." }] } ];
            conversationHistory = savedHistory ? JSON.parse(savedHistory) : initialPrompt;
            if (conversationHistory[0]?.role !== 'user') conversationHistory = initialPrompt;
        }
        loadHistory();

        async function initializeApp() {
            try {
                if (!('webkitSpeechRecognition' in window)) return setUIState('error', "Browser not supported.");
                recognition = new webkitSpeechRecognition();
                Object.assign(recognition, { continuous: false, interimResults: false, lang: 'en-US' });
                recognition.onstart = () => setUIState('listening');
                recognition.onresult = (e) => analyzeWithGemini(e.results[0][0].transcript);
                recognition.onerror = (e) => setUIState(e.error === 'no-speech' ? 'idle' : 'error', "Voice error.");
                recognition.onend = () => sphereContainer.classList.contains('listening') && setUIState('idle');
                
                await setupSpeechSynthesis();
                
                isInitialized = true;
                setUIState('idle');
                console.log("âœ… System Initialized. Bilingual voices are ready.");
            } catch (error) {
                console.error("ðŸ”´ Initialization failed:", error);
                setUIState('error', "Could not initialize voice. Please try reloading.");
            }
        }
        
        function setupSpeechSynthesis() {
            return new Promise((resolve) => {
                const loadVoices = () => {
                    const voices = synthesis.getVoices();
                    if (voices.length > 0) {
                        const englishVoiceNames = ['Google US English', 'Samantha', 'Microsoft Zira Desktop - English (United States)'];
                        for (const name of englishVoiceNames) {
                            const found = voices.find(v => v.name === name && v.lang.startsWith('en'));
                            if (found) { preferredEnglishVoice = found; break; }
                        }
                        if (!preferredEnglishVoice) preferredEnglishVoice = voices.find(v => v.lang.startsWith('en-US'));
                        preferredHindiVoice = voices.find(v => v.lang === 'hi-IN' && v.name.includes('Google')) || voices.find(v => v.lang === 'hi-IN');
                        if (preferredEnglishVoice) console.log(`âœ… English voice: ${preferredEnglishVoice.name}`);
                        if (preferredHindiVoice) console.log(`âœ… Hindi voice: ${preferredHindiVoice.name}`);
                        resolve();
                    }
                };
                if (synthesis.getVoices().length > 0) loadVoices();
                else synthesis.onvoiceschanged = loadVoices;
            });
        }

        function setUIState(state, message = '') {
            sphereContainer.className = state; micButton.disabled = state !== 'idle';
            const statusMessages = { idle: 'Press the mic to speak', listening: 'Listening...', thinking: 'Thinking...', speaking: '...', error: 'An error occurred.' };
            statusText.innerHTML = message || statusMessages[state];
            if (state === 'error') setTimeout(() => setUIState('idle'), 4000);
        }

        micButton.addEventListener('click', async () => {
            if (micButton.disabled) return;
            if (!isInitialized) {
                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (audioContext.state === 'suspended') await audioContext.resume();
                await initializeApp();
                if(isInitialized) recognition.start();
            } else { if (synthesis.speaking) synthesis.cancel(); recognition.start(); }
        });

        async function analyzeWithGemini(userQuery) {
            if (!userQuery.trim()) { setUIState('idle'); return; }
            setUIState('thinking');
            conversationHistory.push({ role: 'user', parts: [{ text: userQuery }] });
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${GEMINI_API_KEY}`, {
                    method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ contents: conversationHistory }),
                });
                if (!response.ok) throw new Error(`API Error: ${response.status}`);
                const result = await response.json();
                const geminiResponseText = result.candidates?.[0]?.content?.parts?.[0]?.text;
                if (!geminiResponseText) throw new Error("Empty response from Gemini.");
                conversationHistory.push({ role: 'model', parts: [{ text: geminiResponseText }] });
                saveHistory();
                const actionRegex = /{\s*"action"[\s\S]*?}/;
                const match = geminiResponseText.match(actionRegex);
                const textToSpeak = geminiResponseText.replace(/`{3}json[\s\S]*?`{3}|`[\s\S]*?`|{\s*"action"[\s\S]*?}/g, '').trim();
                if (match?.[0]) {
                    const action = JSON.parse(match[0]);
                    const purpose = userQuery.toLowerCase().includes('time') ? 'time' : 'weather';
                    await handleAction(action, textToSpeak, purpose);
                } else if (textToSpeak) { await speakAndPlay(textToSpeak); } else { setUIState('idle'); }
            } catch (error) { console.error("ðŸ”´ Gemini/Logic Error:", error); await speakAndPlay("I've run into a problem. Please check the console."); }
        }
        
        async function handleAction(action, spokenConfirmation, purpose) {
            if (spokenConfirmation) await speakAndPlay(spokenConfirmation, true); 
            try {
                switch (action.action) {
                    case 'open_url': if (action.url) window.open(action.url, '_blank'); setUIState('idle'); break;
                    case 'get_info_for_city': await getInfoForCity(action.location, purpose); break;
                    case 'get_local_time': await handleLocalTime(); break;
                    case 'get_date': await handleDate(); break;
                    default: throw new Error(`Unknown action: ${action.action}`);
                }
            } catch (error) { console.error("ðŸ”´ Action Handling Error:", error); await speakAndPlay("I had trouble performing that action."); }
        }

        async function handleLocalTime() { await speakAndPlay(`The current time is ${new Date().toLocaleTimeString('en-US', { hour: 'numeric', minute: 'numeric', hour12: true })}.`); }
        async function handleDate() { await speakAndPlay(`Today is ${new Date().toLocaleDateString('en-US', { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' })}.`); }
        async function getInfoForCity(location, purpose) {
            try {
                setUIState('thinking');
                const response = await fetch(`https://api.weatherapi.com/v1/current.json?key=${WEATHER_API_KEY}&q=${location}`);
                const data = await response.json();
                if (!response.ok || !data.location) throw new Error(data.error?.message || "Invalid location data.");
                const summary = purpose === 'time' ? `The time in ${data.location.name} is ${new Date(data.location.localtime).toLocaleTimeString('en-US', { hour: 'numeric', minute: 'numeric', hour12: true })}.` : `The weather in ${data.location.name} is ${Math.round(data.current.temp_c)}Â° with ${data.current.condition.text}.`;
                await speakAndPlay(summary);
            } catch (error) { console.error("ðŸ”´ Weather/Time Error:", error); await speakAndPlay(`Sorry, I couldn't get that information.`); }
        }

        async function speakAndPlay(text, keepUiBusy = false) {
            if (!text.trim()) { if (!keepUiBusy) setUIState('idle'); return; }
            if (synthesis.speaking) synthesis.cancel();
            return new Promise((resolve) => {
                setUIState('speaking');
                const utterance = new SpeechSynthesisUtterance(text);
                const isHindi = /[\u0900-\u097F]/.test(text);
                if (isHindi && preferredHindiVoice) {
                    utterance.voice = preferredHindiVoice;
                    utterance.lang = 'hi-IN';
                } else {
                    utterance.voice = preferredEnglishVoice;
                    utterance.lang = 'en-US';
                }
                utterance.pitch = 1.0;
                utterance.rate = 1.1;
                utterance.onend = () => { if (!keepUiBusy) setUIState('idle'); resolve(); };
                utterance.onerror = (e) => {
                    console.error("ðŸ”´ Web Speech API Error:", e.error);
                    if (!keepUiBusy) setUIState('error', 'Voice synthesis failed.');
                    resolve();
                };
                synthesis.speak(utterance);
            });
        }
    </script>
</body>
</html
