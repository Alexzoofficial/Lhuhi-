<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced AI Voice Assistant</title>
    
    <style>
        /* CSS with Improved Mic Button */
        body {
            background-color: #000000;
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
            font-family: sans-serif;
        }

        .circle {
            width: 200px;
            height: 200px;
            background: radial-gradient(circle, #007bff, #0056b3);
            border-radius: 50%;
            transition: all 0.3s ease-in-out;
            box-shadow: 0 0 20px #007bff, 0 0 40px #007bff, 0 0 60px #007bff;
        }

        .circle.active {
            transform: scale(1.2);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 25px #007bff, 0 0 50px #007bff; }
            50% { box-shadow: 0 0 50px #00aaff, 0 0 100px #00aaff; }
            100% { box-shadow: 0 0 25px #007bff, 0 0 50px #007bff; }
        }

        .mic-container {
            position: absolute;
            bottom: 40px;
        }

        #mic-button {
            background-color: #ffffff;
            border: none;
            border-radius: 50%;
            padding: 20px;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: 0 0 15px rgba(255, 255, 255, 0.7);
        }

        #mic-button:hover {
            transform: scale(1.1);
            box-shadow: 0 0 25px rgba(0, 123, 255, 0.9);
        }

        #mic-button img {
            width: 50px;
            height: 50px;
            display: block;
        }
    </style>
</head>
<body>

    <div class="circle" id="voice-circle"></div>
    <div class="mic-container">
        <button id="mic-button">
            <img src="https://img.icons8.com/ios-filled/100/000000/microphone.png" alt="Microphone">
        </button>
    </div>

    <script>
        // --- API KEYS AND CONFIGURATION ---
        // !!! IMPORTANT: REPLACE WITH YOUR NEW, SECRET API KEYS !!!
        const GEMINI_API_KEY = 'YOUR_GEMINI_API_KEY';
        const ELEVENLABS_API_KEY = 'YOUR_NEW_11LABS_API_KEY';
        const SERPAPI_API_KEY = 'YOUR_NEW_SERPAPI_API_KEY';
        const ELEVENLABS_VOICE_ID = 'amiAXapsDOAiHJqbsAZj'; // Your chosen voice ID

        // --- DOM ELEMENTS ---
        const micButton = document.getElementById('mic-button');
        const voiceCircle = document.getElementById('voice-circle');

        // --- SPEECH RECOGNITION (INPUT) ---
        if ('webkitSpeechRecognition' in window) {
            const recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.lang = 'hi-IN';

            micButton.addEventListener('click', () => {
                voiceCircle.classList.add('active');
                recognition.start();
            });

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                console.log('User said:', transcript);
                analyzeWithGemini(transcript);
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                voiceCircle.classList.remove('active');
                speakWithElevenLabs("Maaf kijiye, main theek se sun nahi paya.");
            };
        } else {
            alert('Sorry, your browser does not support voice recognition.');
        }

        // --- GEMINI AI (BRAIN) ---
        async function analyzeWithGemini(userQuery) {
            voiceCircle.classList.add('active');
            const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${GEMINI_API_KEY}`;
            
            const prompt = `
                You are a voice assistant's brain. Analyze the user's command: "${userQuery}".
                Your task is to decide the intent and extract data, then respond ONLY with a JSON object.
                Possible intents are: "live_search", "general_query", "write".

                1.  If the query is about current events, prices, live scores, specific locations, or needs up-to-date web information (e.g., "aaj ka mausam", "iphone ka price", "nearest coffee shop"), the action is "live_search".
                    Example: "Bharat ke pradhan mantri kaun hain" -> {"action": "live_search", "data": "Bharat ke pradhan mantri kaun hain"}

                2.  If the query is a general knowledge question, a conversation, or a command you can answer directly (e.g., "gravity kya hai", "ek kahani sunao"), the action is "general_query".
                    Example: "pyar kya hai" -> {"action": "general_query", "data": "Pyar ek gehra aur anokha ehsaas hai..."}

                3.  If the user asks to write something.
                    Example: "likho main theek hun" -> {"action": "write", "data": "main theek hun"}

                User command: "${userQuery}". Provide only the JSON object.
            `;
            
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] }),
                });

                const result = await response.json();
                const geminiResponseText = result.candidates[0].content.parts[0].text;
                const cleanJsonString = geminiResponseText.replace(/```json\n|\n```/g, '').trim();
                const actionObject = JSON.parse(cleanJsonString);
                
                console.log('Gemini action plan:', actionObject);
                await performAction(actionObject);

            } catch (error) {
                console.error("Error with Gemini:", error);
                await speakWithElevenLabs("Kuchh takneeki samasya aa gayi hai.");
                voiceCircle.classList.remove('active');
            }
        }

        // --- ACTION HANDLER ---
        async function performAction(actionObject) {
            const { action, data } = actionObject;

            switch (action) {
                case 'live_search':
                    await performSerpAPISearch(data);
                    break;
                case 'write':
                     navigator.clipboard.writeText(data);
                     await speakWithElevenLabs(`Maine, "${data}", copy kar liya hai.`);
                     break;
                case 'general_query':
                default:
                    await speakWithElevenLabs(data);
            }
        }

        // --- SERPAPI INTEGRATION (REAL-TIME SEARCH) ---
        async function performSerpAPISearch(query) {
             console.log(`Searching SerpAPI for: ${query}`);
             // Note: A backend proxy is recommended to hide the API key in a real application.
             const API_URL = `https://serpapi.com/search.json?q=${encodeURIComponent(query)}&api_key=${SERPAPI_API_KEY}`;
             
             try {
                const response = await fetch(API_URL);
                const searchResults = await response.json();

                let answer = "Mujhe iska jawab nahi mila.";
                // Try to find a direct answer (answer box, knowledge graph)
                if (searchResults.answer_box && searchResults.answer_box.answer) {
                    answer = searchResults.answer_box.answer;
                } else if (searchResults.answer_box && searchResults.answer_box.snippet) {
                    answer = searchResults.answer_box.snippet;
                } else if (searchResults.knowledge_graph && searchResults.knowledge_graph.description) {
                    answer = searchResults.knowledge_graph.description;
                } else if (searchResults.organic_results && searchResults.organic_results[0].snippet) {
                    // Fallback to the snippet of the first result
                    answer = searchResults.organic_results[0].snippet;
                }
                
                console.log("SerpAPI Answer:", answer);
                await speakWithElevenLabs(answer);

             } catch(error) {
                console.error("Error with SerpAPI:", error);
                await speakWithElevenLabs("Internet search mein samasya aa rahi hai.");
                voiceCircle.classList.remove('active');
             }
        }

        // --- ELEVENLABS TTS (VOICE OUTPUT) ---
        async function speakWithElevenLabs(text) {
            voiceCircle.classList.add('active');
            const API_URL = `https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`;
            
            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: {
                        'Accept': 'audio/mpeg',
                        'Content-Type': 'application/json',
                        'xi-api-key': ELEVENLABS_API_KEY,
                    },
                    body: JSON.stringify({
                        text: text,
                        model_id: 'eleven_multilingual_v2',
                        voice_settings: {
                            stability: 0.5,
                            similarity_boost: 0.75,
                        },
                    }),
                });

                if (!response.ok) {
                    throw new Error(`ElevenLabs API Error: ${response.statusText}`);
                }

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                audio.play();

                // Wait for the audio to finish playing before stopping the animation
                audio.onended = () => {
                    voiceCircle.classList.remove('active');
                };

            } catch(error) {
                console.error("Error with ElevenLabs:", error);
                voiceCircle.classList.remove('active');
            }
        }
    </script>
</body>
</html>
